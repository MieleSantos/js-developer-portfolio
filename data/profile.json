{
  "name": "Miele Silva",
  "photo": "https://avatars.githubusercontent.com/u/14097351?v=4",
  "job": "Desenvolvedor Back-end",
  "location": "São Carlos - SP",
  "phone": "(16) 988138285",
  "email": "mielesnts@gmail.com",
  "skills": {
    "hardSkills": [
      {
        "name": "Python",
        "logo": "https://raw.githubusercontent.com/digitalinnovationone/js-developer-portfolio/main/data/imgs/python.png"
      },
      {
        "name": "Fastapi",
        "logo": "https://raw.githubusercontent.com/digitalinnovationone/js-developer-portfolio/main/data/imgs/icons/fastapi.svg"
      },
      {
        "name": "Docker",
        "logo": "https://raw.githubusercontent.com/digitalinnovationone/js-developer-portfolio/main/data/imgs/docker.png"
      },
      {
        "name": "Mongodb",
        "logo": "https://raw.githubusercontent.com/digitalinnovationone/js-developer-portfolio/main/data/imgs/mongodb.png"
      },
      {
        "name": "Postgresql",
        "logo": "https://raw.githubusercontent.com/digitalinnovationone/js-developer-portfolio/main/data/imgs/postgresql.png"
      }
    ],
    "softSkills": [
      "Empatia",
      "Prestativo",
      "Trabalho em equipe",
      "Flexibilidade",
      "Organização"
    ]
  },
  "languages": [
    "Português BR"
  ],
  "portfolio": [
    {
      "name": "Curso Ministrado na DIO para a criação de uma Pokedex",
      "url": "https://github.com/MieleSantos/pokedex",
      "github": true
    },
    {
      "name": "Curso Ministrado na DIO para a criação de uma página de portfolio",
      "url": "https://github.com/MieleSantos/js-developer-portfolio",
      "github": true
    }
  ],
  "professionalExperience": [
    {
      "name": "Analista de Sistemas / juristec+",
      "period": "2018 - 2024",
      "description": "Atuou em projetos relacionados a criação, integração e manutenção de chatbots, testes unitários, curadoria de banco de conhecimento, uso de ferramentas de NLP para extração automática de informações de grandes volumes de dados, criação/manutenção de web crawlers, pipelines de dados para captura, processamento e armazenamento de dados e criação/manutenção de API"
    }
   
  ]
}